{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hr17uYPX85vm",
    "outputId": "bb6051ff-e154-4539-f934-be4e3d28b775",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amd64\n"
     ]
    }
   ],
   "source": [
    "!dpkg --print-architecture\n",
    "\n",
    "# Download ffmpeg\n",
    "\n",
    "#!wget https://johnvansickle.com/ffmpeg/builds/ffmpeg-git-amd64-static.tar.xz\n",
    "#!tar -xf ffmpeg-git-amd64-static.tar.xz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "LcmKQgf4Fbw2",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch as T\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.autograd import Variable\n",
    "from skimage.metrics import structural_similarity\n",
    "import imageio.v3 as iio\n",
    "T.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "71ZpaFgEFwQk",
    "outputId": "59e7e39c-6b4e-4fab-ad2e-e86116582f6c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./WUzgd7C1pWA.mp4\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets.utils import download_url\n",
    "\n",
    "download_url(\n",
    "    \"https://github.com/pytorch/vision/blob/main/test/assets/videos/WUzgd7C1pWA.mp4?raw=true\",\n",
    "    \".\",\n",
    "    \"WUzgd7C1pWA.mp4\"\n",
    ")\n",
    "video_path = \"./WUzgd7C1pWA.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vo1dwfHa9zvy",
    "outputId": "01c03960-437e-4abc-93f9-8da0fd03e96a",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg version n6.0 Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with gcc 12.2.1 (GCC) 20230201\n",
      "  configuration: --prefix=/usr --disable-debug --disable-static --disable-stripping --enable-amf --enable-avisynth --enable-cuda-llvm --enable-lto --enable-fontconfig --enable-gmp --enable-gnutls --enable-gpl --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libdav1d --enable-libdrm --enable-libfreetype --enable-libfribidi --enable-libgsm --enable-libiec61883 --enable-libjack --enable-libjxl --enable-libmfx --enable-libmodplug --enable-libmp3lame --enable-libopencore_amrnb --enable-libopencore_amrwb --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librav1e --enable-librsvg --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtheora --enable-libv4l2 --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxcb --enable-libxml2 --enable-libxvid --enable-libzimg --enable-nvdec --enable-nvenc --enable-opencl --enable-opengl --enable-shared --enable-version3 --enable-vulkan\n",
      "  libavutil      58.  2.100 / 58.  2.100\n",
      "  libavcodec     60.  3.100 / 60.  3.100\n",
      "  libavformat    60.  3.100 / 60.  3.100\n",
      "  libavdevice    60.  1.100 / 60.  1.100\n",
      "  libavfilter     9.  3.100 /  9.  3.100\n",
      "  libswscale      7.  1.100 /  7.  1.100\n",
      "  libswresample   4. 10.100 /  4. 10.100\n",
      "  libpostproc    57.  1.100 / 57.  1.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'WUzgd7C1pWA.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf56.25.101\n",
      "  Duration: 00:00:10.91, start: 0.000000, bitrate: 652 kb/s\n",
      "  Stream #0:0[0x1](und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(progressive), 340x256 [SAR 1:1 DAR 85:64], 562 kb/s, 29.97 fps, 29.97 tbr, 30k tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "  Stream #0:1[0x2](eng): Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, mono, fltp, 80 kb/s (default)\n",
      "    Metadata:\n",
      "      handler_name    : SoundHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (h264 (native) -> h264 (libx264))\n",
      "  Stream #0:1 -> #0:1 (aac (native) -> aac (native))\n",
      "Press [q] to stop, [?] for help\n",
      "\u001b[1;36m[libx264 @ 0x5632d82d7380] \u001b[0musing SAR=1/1\n",
      "\u001b[1;36m[libx264 @ 0x5632d82d7380] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "\u001b[1;36m[libx264 @ 0x5632d82d7380] \u001b[0mprofile Constrained Baseline, level 1.3, 4:2:0, 8-bit\n",
      "\u001b[1;36m[libx264 @ 0x5632d82d7380] \u001b[0m264 - core 164 r3095 baee400 - H.264/MPEG-4 AVC codec - Copyleft 2003-2022 - http://www.videolan.org/x264.html - options: cabac=0 ref=1 deblock=0:0:0 analyse=0:0 me=dia subme=0 psy=1 psy_rd=1.00:0.00 mixed_ref=0 me_range=16 chroma_me=1 trellis=0 8x8dct=0 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=0 threads=8 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=0 weightp=0 keyint=250 keyint_min=25 scenecut=0 intra_refresh=0 rc=crf mbtree=0 crf=35.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=0\n",
      "Output #0, mp4, to 'output.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf60.3.100\n",
      "  Stream #0:0(und): Video: h264 (avc1 / 0x31637661), yuv420p(progressive), 340x256 [SAR 1:1 DAR 85:64], q=2-31, 29.97 fps, 30k tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc60.3.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
      "  Stream #0:1(eng): Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, mono, fltp, 69 kb/s (default)\n",
      "    Metadata:\n",
      "      handler_name    : SoundHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc60.3.100 aac\n",
      "frame=  327 fps=0.0 q=-1.0 Lsize=     455kB time=00:00:10.88 bitrate= 342.6kbits/s speed=34.1x    \n",
      "video:352kB audio:92kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 2.371399%\n",
      "\u001b[1;36m[libx264 @ 0x5632d82d7380] \u001b[0mframe I:2     Avg QP:33.00  size:  5878\n",
      "\u001b[1;36m[libx264 @ 0x5632d82d7380] \u001b[0mframe P:325   Avg QP:38.08  size:  1071\n",
      "\u001b[1;36m[libx264 @ 0x5632d82d7380] \u001b[0mmb I  I16..4: 100.0%  0.0%  0.0%\n",
      "\u001b[1;36m[libx264 @ 0x5632d82d7380] \u001b[0mmb P  I16..4:  8.7%  0.0%  0.0%  P16..4: 46.7%  0.0%  0.0%  0.0%  0.0%    skip:44.6%\n",
      "\u001b[1;36m[libx264 @ 0x5632d82d7380] \u001b[0mcoded y,uvDC,uvAC intra: 26.3% 24.2% 2.7% inter: 16.0% 6.0% 0.1%\n",
      "\u001b[1;36m[libx264 @ 0x5632d82d7380] \u001b[0mi16 v,h,dc,p: 25% 34% 25% 16%\n",
      "\u001b[1;36m[libx264 @ 0x5632d82d7380] \u001b[0mi8c dc,h,v,p: 63% 19% 13%  6%\n",
      "\u001b[1;36m[libx264 @ 0x5632d82d7380] \u001b[0mkb/s:263.94\n",
      "\u001b[1;36m[aac @ 0x5632d829ec40] \u001b[0mQavg: 124.327\n"
     ]
    }
   ],
   "source": [
    "!rm output.mp4\n",
    "!ffmpeg -i WUzgd7C1pWA.mp4 -vcodec libx264 -preset ultrafast -crf 35 -acodec aac output.mp4 > /dev/null\n",
    "#!ffmpeg -i WUzgd7C1pWA.mp4 -b:v 2M output.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eUtk7m3p7MVz",
    "outputId": "f2d5c8ea-9415-40fe-bb1e-6fe06df4b2ee",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg version N-66244-g468615f204-static https://johnvansickle.com/ffmpeg/  Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with gcc 8 (Debian 8.3.0-6)\n",
      "  configuration: --enable-gpl --enable-version3 --enable-static --disable-debug --disable-ffplay --disable-indev=sndio --disable-outdev=sndio --cc=gcc --enable-fontconfig --enable-frei0r --enable-gnutls --enable-gmp --enable-libgme --enable-gray --enable-libaom --enable-libfribidi --enable-libass --enable-libvmaf --enable-libfreetype --enable-libmp3lame --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-librubberband --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libvorbis --enable-libopus --enable-libtheora --enable-libvidstab --enable-libvo-amrwbenc --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libdav1d --enable-libxvid --enable-libzvbi --enable-libzimg\n",
      "  libavutil      58. 13.101 / 58. 13.101\n",
      "  libavcodec     60. 21.100 / 60. 21.100\n",
      "  libavformat    60.  9.100 / 60.  9.100\n",
      "  libavdevice    60.  2.100 / 60.  2.100\n",
      "  libavfilter     9.  8.102 /  9.  8.102\n",
      "  libswscale      7.  3.100 /  7.  3.100\n",
      "  libswresample   4. 11.100 /  4. 11.100\n",
      "  libpostproc    57.  2.100 / 57.  2.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'WUzgd7C1pWA.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf56.25.101\n",
      "  Duration: 00:00:10.91, start: 0.000000, bitrate: 652 kb/s\n",
      "  Stream #0:0[0x1](und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(progressive), 340x256 [SAR 1:1 DAR 85:64], 562 kb/s, 29.97 fps, 29.97 tbr, 30k tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "  Stream #0:1[0x2](eng): Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, mono, fltp, 80 kb/s (default)\n",
      "    Metadata:\n",
      "      handler_name    : SoundHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "Input #1, mov,mp4,m4a,3gp,3g2,mj2, from 'output.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf60.3.100\n",
      "  Duration: 00:00:10.91, start: 0.000000, bitrate: 341 kb/s\n",
      "  Stream #1:0[0x1](und): Video: h264 (Constrained Baseline) (avc1 / 0x31637661), yuv420p(progressive), 340x256 [SAR 1:1 DAR 85:64], 264 kb/s, 29.97 fps, 29.97 tbr, 30k tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc60.3.100 libx264\n",
      "  Stream #1:1[0x2](eng): Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, mono, fltp, 69 kb/s (default)\n",
      "    Metadata:\n",
      "      handler_name    : SoundHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "Stream mapping:\n",
      "  Stream #0:0 (h264) -> libvmaf (graph 0)\n",
      "  Stream #1:0 (h264) -> libvmaf (graph 0)\n",
      "  libvmaf:default (graph 0) -> Stream #0:0 (wrapped_avframe)\n",
      "  Stream #0:1 -> #0:1 (aac (native) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, null, to 'pipe:':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf60.9.100\n",
      "  Stream #0:0: Video: wrapped_avframe, yuv420p(progressive), 340x256 [SAR 1:1 DAR 85:64], q=2-31, 200 kb/s, 29.97 fps, 29.97 tbn\n",
      "    Metadata:\n",
      "      encoder         : Lavc60.21.100 wrapped_avframe\n",
      "  Stream #0:1(eng): Audio: pcm_s16le, 48000 Hz, mono, s16, 768 kb/s (default)\n",
      "    Metadata:\n",
      "      handler_name    : SoundHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc60.21.100 pcm_s16le\n",
      "\u001b[1;35m[out#0/null @ 0x8cc3fc0] \u001b[0mvideo:153kB audio:1022kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n",
      "frame=  327 fps=0.0 q=-0.0 Lsize=N/A time=00:00:10.88 bitrate=N/A speed=82.1x    \n",
      "\u001b[1;32m[Parsed_libvmaf_0 @ 0x8d8a500] \u001b[0mVMAF score: 91.079735\n"
     ]
    }
   ],
   "source": [
    "!./ffmpeg-git-20230621-amd64-static/ffmpeg -i WUzgd7C1pWA.mp4 -i output.mp4 -lavfi libvmaf=\"n_threads=1:n_subsample=10220\" -f null -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "IDXqFCeJIP2q",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import subprocess\n",
    "def compare(ImageAPath, ImageBPath):\n",
    "    cmd = \" \".join([\"./ffmpeg-git-20230621-amd64-static/ffmpeg -i\", ImageAPath, \"-i\", ImageBPath, \"-lavfi libvmaf='n_threads=16' -f null -\"])\n",
    "    x = subprocess.getoutput(cmd);\n",
    "    return float(x.split()[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PCH_WHlCIbSB",
    "outputId": "e14395f1-3863-4ed9-abdc-98c77a82596e",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78.146123"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare(\"./WUzgd7C1pWA.mp4\", \"./output.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Copyright (c) Meta Platforms, Inc. and affiliates.\n",
    "#\n",
    "# This source code is licensed under the MIT license found in the\n",
    "# LICENSE file in the root directory of this source tree.\n",
    "\n",
    "\n",
    "# from https://github.com/toshas/torch_truncnorm\n",
    "\n",
    "import math\n",
    "from numbers import Number\n",
    "\n",
    "import torch\n",
    "from torch.distributions import constraints, Distribution\n",
    "from torch.distributions.utils import broadcast_all\n",
    "\n",
    "CONST_SQRT_2 = math.sqrt(2)\n",
    "CONST_INV_SQRT_2PI = 1 / math.sqrt(2 * math.pi)\n",
    "CONST_INV_SQRT_2 = 1 / math.sqrt(2)\n",
    "CONST_LOG_INV_SQRT_2PI = math.log(CONST_INV_SQRT_2PI)\n",
    "CONST_LOG_SQRT_2PI_E = 0.5 * math.log(2 * math.pi * math.e)\n",
    "\n",
    "\n",
    "class TruncatedStandardNormal(Distribution):\n",
    "    \"\"\"Truncated Standard Normal distribution.\n",
    "\n",
    "    Source: https://people.sc.fsu.edu/~jburkardt/presentations/truncated_normal.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    arg_constraints = {\n",
    "        \"a\": constraints.real,\n",
    "        \"b\": constraints.real,\n",
    "    }\n",
    "    has_rsample = True\n",
    "    eps = 1e-6\n",
    "\n",
    "    def __init__(self, a, b, validate_args=None):\n",
    "        self.a, self.b = broadcast_all(a, b)\n",
    "        if isinstance(a, Number) and isinstance(b, Number):\n",
    "            batch_shape = torch.Size()\n",
    "        else:\n",
    "            batch_shape = self.a.size()\n",
    "        super(TruncatedStandardNormal, self).__init__(\n",
    "            batch_shape, validate_args=validate_args\n",
    "        )\n",
    "        if self.a.dtype != self.b.dtype:\n",
    "            raise ValueError(\"Truncation bounds types are different\")\n",
    "        if any(\n",
    "            (self.a >= self.b)\n",
    "            .view(\n",
    "                -1,\n",
    "            )\n",
    "            .tolist()\n",
    "        ):\n",
    "            raise ValueError(\"Incorrect truncation range\")\n",
    "        eps = self.eps\n",
    "        self._dtype_min_gt_0 = eps\n",
    "        self._dtype_max_lt_1 = 1 - eps\n",
    "        self._little_phi_a = self._little_phi(self.a)\n",
    "        self._little_phi_b = self._little_phi(self.b)\n",
    "        self._big_phi_a = self._big_phi(self.a)\n",
    "        self._big_phi_b = self._big_phi(self.b)\n",
    "        self._Z = (self._big_phi_b - self._big_phi_a).clamp(eps, 1 - eps)\n",
    "        self._log_Z = self._Z.log()\n",
    "        little_phi_coeff_a = torch.nan_to_num(self.a, nan=math.nan)\n",
    "        little_phi_coeff_b = torch.nan_to_num(self.b, nan=math.nan)\n",
    "        self._lpbb_m_lpaa_d_Z = (\n",
    "            self._little_phi_b * little_phi_coeff_b\n",
    "            - self._little_phi_a * little_phi_coeff_a\n",
    "        ) / self._Z\n",
    "        self._mean = -(self._little_phi_b - self._little_phi_a) / self._Z\n",
    "        self._variance = (\n",
    "            1\n",
    "            - self._lpbb_m_lpaa_d_Z\n",
    "            - ((self._little_phi_b - self._little_phi_a) / self._Z) ** 2\n",
    "        )\n",
    "        self._entropy = CONST_LOG_SQRT_2PI_E + self._log_Z - 0.5 * self._lpbb_m_lpaa_d_Z\n",
    "\n",
    "    @constraints.dependent_property\n",
    "    def support(self):\n",
    "        return constraints.interval(self.a, self.b)\n",
    "\n",
    "    @property\n",
    "    def mean(self):\n",
    "        return self._mean\n",
    "\n",
    "    @property\n",
    "    def variance(self):\n",
    "        return self._variance\n",
    "\n",
    "    @property\n",
    "    def entropy(self):\n",
    "        return self._entropy\n",
    "\n",
    "    @property\n",
    "    def auc(self):\n",
    "        return self._Z\n",
    "\n",
    "    @staticmethod\n",
    "    def _little_phi(x):\n",
    "        return (-(x**2) * 0.5).exp() * CONST_INV_SQRT_2PI\n",
    "\n",
    "    def _big_phi(self, x):\n",
    "        phi = 0.5 * (1 + (x * CONST_INV_SQRT_2).erf())\n",
    "        return phi.clamp(self.eps, 1 - self.eps)\n",
    "\n",
    "    @staticmethod\n",
    "    def _inv_big_phi(x):\n",
    "        return CONST_SQRT_2 * (2 * x - 1).erfinv()\n",
    "\n",
    "    def cdf(self, value):\n",
    "        if self._validate_args:\n",
    "            self._validate_sample(value)\n",
    "        return ((self._big_phi(value) - self._big_phi_a) / self._Z).clamp(0, 1)\n",
    "\n",
    "    def icdf(self, value):\n",
    "        y = self._big_phi_a + value * self._Z\n",
    "        y = y.clamp(self.eps, 1 - self.eps)\n",
    "        return self._inv_big_phi(y)\n",
    "\n",
    "    def log_prob(self, value):\n",
    "        if self._validate_args:\n",
    "            self._validate_sample(value)\n",
    "        return CONST_LOG_INV_SQRT_2PI - self._log_Z - (value**2) * 0.5\n",
    "\n",
    "    def rsample(self, sample_shape=None):\n",
    "        if sample_shape is None:\n",
    "            sample_shape = torch.Size([])\n",
    "        shape = self._extended_shape(sample_shape)\n",
    "        p = torch.empty(shape, device=self.a.device).uniform_(\n",
    "            self._dtype_min_gt_0, self._dtype_max_lt_1\n",
    "        )\n",
    "        return self.icdf(p)\n",
    "\n",
    "\n",
    "class TruncatedNormal(TruncatedStandardNormal):\n",
    "    \"\"\"Truncated Normal distribution.\n",
    "\n",
    "    https://people.sc.fsu.edu/~jburkardt/presentations/truncated_normal.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    has_rsample = True\n",
    "\n",
    "    def __init__(self, loc, scale, a, b, validate_args=None):\n",
    "        scale = scale.clamp_min(self.eps)\n",
    "        self.loc, self.scale, a, b = broadcast_all(loc, scale, a, b)\n",
    "        self._non_std_a = a\n",
    "        self._non_std_b = b\n",
    "        a = (a - self.loc) / self.scale\n",
    "        b = (b - self.loc) / self.scale\n",
    "        super(TruncatedNormal, self).__init__(a, b, validate_args=validate_args)\n",
    "        self._log_scale = self.scale.log()\n",
    "        self._mean = self._mean * self.scale + self.loc\n",
    "        self._variance = self._variance * self.scale**2\n",
    "        self._entropy += self._log_scale\n",
    "\n",
    "    def _to_std_rv(self, value):\n",
    "        return (value - self.loc) / self.scale\n",
    "\n",
    "    def _from_std_rv(self, value):\n",
    "        return value * self.scale + self.loc\n",
    "\n",
    "    def cdf(self, value):\n",
    "        return super(TruncatedNormal, self).cdf(self._to_std_rv(value))\n",
    "\n",
    "    def icdf(self, value):\n",
    "        sample = self._from_std_rv(super().icdf(value))\n",
    "\n",
    "        # clamp data but keep gradients\n",
    "        sample_clip = torch.stack(\n",
    "            [sample.detach(), self._non_std_a.detach().expand_as(sample)], 0\n",
    "        ).max(0)[0]\n",
    "        sample_clip = torch.stack(\n",
    "            [sample_clip, self._non_std_b.detach().expand_as(sample)], 0\n",
    "        ).min(0)[0]\n",
    "        sample.data.copy_(sample_clip)\n",
    "        return sample\n",
    "\n",
    "    def log_prob(self, value):\n",
    "        value = self._to_std_rv(value)\n",
    "        return super(TruncatedNormal, self).log_prob(value) - self._log_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mudiko/.local/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/mudiko/.local/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "resnet50 = models.resnet50(pretrained=True)\n",
    "modules=list(resnet50.children())[:-1]\n",
    "resnet50 = nn.Sequential(*modules)\n",
    "\n",
    "# Set to false to stop training image part\n",
    "for p in resnet50.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "modules = []\n",
    "modules.append(nn.Linear(2048, 10))\n",
    "modules.append(nn.ReLU())\n",
    "encoder = nn.Sequential(*modules)\n",
    "\n",
    "# Set to false to stop training image part\n",
    "for p in resnet50.parameters():\n",
    "    p.requires_grad = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L80JDPWFIgSa",
    "outputId": "98aa6e12-42a7-41a2-9c98-f929b68ee7c2",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: ffmpeg-bitrate-stats in /home/mudiko/.local/lib/python3.11/site-packages (0.4.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install ffmpeg-bitrate-stats\n",
    "from ffmpeg_bitrate_stats import BitrateStats\n",
    "\n",
    "import os\n",
    "import gym\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "\n",
    "import subprocess\n",
    "\n",
    "game_steps = 5\n",
    "\n",
    "import time\n",
    "\n",
    "class VideoEncodingEnvironment(gym.Env):\n",
    "    def __init__(self, target_video):\n",
    "        super(VideoEncodingEnvironment, self).__init__()\n",
    "\n",
    "        self.target_video = target_video  # Target video representation\n",
    "        #self.max_steps = max_steps  # Maximum number of steps for encoding\n",
    "\n",
    "        self.current_step = 0  # Current step in the encoding process\n",
    "        \n",
    "        self.size = os.stat(target_video).st_size  # Current video representation\n",
    "        self.initial_size = self.size\n",
    "        \n",
    "        ffbs = BitrateStats(target_video)\n",
    "        ffbs.calculate_statistics()\n",
    "        \n",
    "        #RESNET50 can be replaced by something faster and better\n",
    "        \n",
    "        self.create_embedding()\n",
    "\n",
    "        self.bitrate = ffbs.avg_bitrate\n",
    "\n",
    "        self.quality = 100\n",
    "        \n",
    "        self.initial_bitrate = 0\n",
    "        \n",
    "        self.prev_score = 0\n",
    "\n",
    "\n",
    "\n",
    "    def step(self, action):\n",
    "        # Update step count\n",
    "        self.current_step += 1\n",
    "        \n",
    "        action = action * self.initial_bitrate * 1000\n",
    "\n",
    "        # Calculate quality\n",
    "        os.remove(\"./output.mp4\") if os.path.exists(\"./output.mp4\") else None\n",
    "        cmd = \" \".join([\"ffmpeg -i\", self.target_video, \"-vcodec libx264\",\"-b:v\", str(int(action)), \"./output.mp4\", \"-hide_banner\", \"-preset ultrafast\", \"-loglevel error\"])\n",
    "        x = subprocess.run(cmd, shell = True, stdout = subprocess.DEVNULL, stderr=subprocess.PIPE)\n",
    "        if x.stderr.decode() != \"\":\n",
    "            print(\"Error\")\n",
    "            self.quality = 0\n",
    "            state = np.array([[self.current_step, self.initial_bitrate, self. initial_size, self.bitrate, 100 * (self.quality - 85), self.bitrate/self.initial_bitrate,self.size]])\n",
    "            state = np.concatenate((state, self.embed.reshape((1,-1)).detach().numpy()), axis = 1).reshape(-1)\n",
    "            return state, -5000, True, _\n",
    "\n",
    "        ffbs = BitrateStats(\"./output.mp4\")\n",
    "        ffbs.calculate_statistics()\n",
    "        self.bitrate = ffbs.avg_bitrate\n",
    "        \n",
    "        last_quality = self.quality\n",
    "        self.quality = compare(self.target_video, './output.mp4')\n",
    "\n",
    "        # Update size\n",
    "        self.size = os.stat(\"./output.mp4\").st_size\n",
    "\n",
    "        state = np.array([[self.current_step, self.initial_bitrate, self. initial_size, self.bitrate, 100 * (self.quality - 85),self.bitrate/self.initial_bitrate, self.size]])\n",
    "        state = np.concatenate((state, self.embed.reshape((1,-1)).detach().numpy()), axis = 1).reshape(-1)\n",
    "        \n",
    "        \n",
    "        target_reached = self.quality > 84 and self.quality < 86\n",
    "        \n",
    "        improvement = abs(last_quality - 85) - abs(self.quality - 85)\n",
    "        # Reward\n",
    "        if improvement < 0:\n",
    "            reward = -500\n",
    "        \n",
    "\n",
    "        else:\n",
    "\n",
    "            reward = improvement - abs(self.quality - 85)\n",
    "        \"\"\"\n",
    "\n",
    "        if self.quality > 92:\n",
    "            score -= (self.quality - 92) * 5\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.bitrate > self.initial_bitrate:\n",
    "            print(\"WTF too high\")\n",
    "            self.quality = 0\n",
    "            state = np.array([[self.current_step, self.initial_bitrate, self. initial_size, self.bitrate, 100 * (self.quality - 85), self.bitrate/self.initial_bitrate, self.size]])\n",
    "            state = np.concatenate((state, self.embed.reshape((1,-1)).detach().numpy()), axis = 1).reshape(-1)\n",
    "            return state, -5000, True, _\n",
    "            \n",
    "        \n",
    "        #Give bonus for reaching target\n",
    "        if target_reached:\n",
    "            reward = reward + (100 * (game_steps + 1 - self.current_step)) \n",
    "        \n",
    "        #reward = score - self.prev_score - ((abs(self.quality - 85)/1.5) ** 2 ) - 10\n",
    "        self.prev_score = reward\n",
    "        return state, reward, self.current_step > (game_steps - 1) or target_reached, _\n",
    "\n",
    "    def create_embedding(self):\n",
    "        #Create embedding for a single image\n",
    "        from PIL import Image\n",
    "        #Extract the first frame\n",
    "        #Can be possible to do more efficiently without iio.imiter\n",
    "        iio.imwrite(\"extracted.jpg\", list(iio.imiter(self.target_video))[0])\n",
    "        import torchvision.transforms as transforms\n",
    "        transform = transforms.Compose([transforms.PILToTensor()])\n",
    "        img = Image.open(\"extracted.jpg\")\n",
    "        tensor = transform(img)\n",
    "        tensor = tensor.unsqueeze(0).float()\n",
    "        self.embed = encoder(resnet50(tensor).squeeze())\n",
    "\n",
    "    def reset(self, target_video):\n",
    "        self.target_video = target_video\n",
    "        self.current_step = 0  # Current step in the encoding process\n",
    "        self.prev_score = 0\n",
    "        self.reward = 0\n",
    "        self.size = os.stat(self.target_video).st_size  # Current video representation\n",
    "        self.initial_size = self.size\n",
    "\n",
    "\n",
    "        ffbs = BitrateStats(self.target_video)\n",
    "        ffbs.calculate_statistics()\n",
    "        self.bitrate = ffbs.avg_bitrate\n",
    "        \n",
    "        self.initial_bitrate = self.bitrate\n",
    "\n",
    "\n",
    "        self.quality = 100\n",
    "\n",
    "        self.create_embedding()\n",
    "        state = np.array([[self.current_step, self.initial_bitrate, self. initial_size, self.bitrate, 100 * (self.quality - 85), self.bitrate/self.initial_bitrate,self.size]])\n",
    "        state = np.concatenate((state, self.embed.reshape((1,-1)).detach().numpy()), axis = 1).reshape(-1)\n",
    "\n",
    "        return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "## takes in a module and applies the specified weight initialization\n",
    "def weights_init_normal(m):\n",
    "    '''Takes in a module and initializes all linear layers with weight\n",
    "       values taken from a normal distribution.'''\n",
    "\n",
    "    classname = m.__class__.__name__\n",
    "    # for every Linear layer in a model\n",
    "    if classname.find('Linear') != -1:\n",
    "        y = m.in_features\n",
    "    # m.weight.data shoud be taken from a normal distribution\n",
    "        m.weight.data.normal_(0.0,1/np.sqrt(y))\n",
    "    # m.bias.data should be 0\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZYMHfAMkQTql",
    "outputId": "21d49f84-75de-4ad1-c82a-5c05807854b5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘ppo’: File exists\n"
     ]
    }
   ],
   "source": [
    "%mkdir ppo\n",
    "import os\n",
    "import numpy as np\n",
    "import torch as T\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.distributions.normal import Normal\n",
    "from torch.distributions.beta import Beta\n",
    "import math\n",
    "\n",
    "class PPOMemory:\n",
    "    def __init__(self, batch_size):\n",
    "        self.states = []\n",
    "        self.probs = []\n",
    "        self.vals = []\n",
    "        self.actions = []\n",
    "        self.rewards = []\n",
    "        self.dones = []\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def generate_batches(self):\n",
    "        n_states = len(self.states)\n",
    "        batch_start = np.arange(0, n_states, self.batch_size)\n",
    "        indices = np.arange(n_states, dtype=np.int64)\n",
    "        np.random.shuffle(indices)\n",
    "        batches = [indices[i:i+self.batch_size] for i in batch_start]\n",
    "\n",
    "        return np.array(self.states),\\\n",
    "                np.array(self.actions),\\\n",
    "                np.array(self.probs),\\\n",
    "                np.array(self.vals),\\\n",
    "                np.array(self.rewards),\\\n",
    "                np.array(self.dones),\\\n",
    "                batches\n",
    "\n",
    "    def store_memory(self, state, action, probs, vals, reward, done):\n",
    "        self.states.append(state)\n",
    "        self.actions.append(action)\n",
    "        self.probs.append(probs)\n",
    "        self.vals.append(vals)\n",
    "        self.rewards.append(reward)\n",
    "        self.dones.append(done)\n",
    "\n",
    "    def clear_memory(self):\n",
    "        self.states = []\n",
    "        self.probs = []\n",
    "        self.actions = []\n",
    "        self.rewards = []\n",
    "        self.dones = []\n",
    "        self.vals = []\n",
    "\n",
    "class ActorNetwork(nn.Module):\n",
    "    def __init__(self, n_actions, input_dims, alpha,\n",
    "            fc1_dims=256, fc2_dims=256, chkpt_dir='ppo'):\n",
    "        super(ActorNetwork, self).__init__()\n",
    "\n",
    "        self.checkpoint_file = os.path.join(chkpt_dir, 'actor_torch_ppo')\n",
    "        self.actor = nn.Sequential(\n",
    "                nn.Linear(input_dims, fc1_dims),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(fc1_dims, fc2_dims),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(fc1_dims, fc2_dims),\n",
    "                nn.Sigmoid(),\n",
    "                nn.Linear(fc2_dims, 2)\n",
    "        )\n",
    "        \n",
    "\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=alpha)\n",
    "        self.device = T.device('cuda:0' if T.cuda.is_available() else 'cpu')\n",
    "        self.to(self.device)\n",
    "\n",
    "    def forward(self, state):\n",
    "        dist = self.actor(state)\n",
    "        dist = torch.abs(dist).reshape(-1,2)\n",
    "        dist = Normal(dist[:,0] , dist[:,1])\n",
    "        print(dist)\n",
    "        return dist\n",
    "\n",
    "    def save_checkpoint(self):\n",
    "        T.save(self.state_dict(), self.checkpoint_file)\n",
    "\n",
    "    def load_checkpoint(self):\n",
    "        self.load_state_dict(T.load(self.checkpoint_file))\n",
    "\n",
    "class CriticNetwork(nn.Module):\n",
    "    def __init__(self, input_dims, alpha, fc1_dims=256, fc2_dims=256,\n",
    "            chkpt_dir='ppo'):\n",
    "        super(CriticNetwork, self).__init__()\n",
    "\n",
    "        self.checkpoint_file = os.path.join(chkpt_dir, 'critic_torch_ppo')\n",
    "        self.critic = nn.Sequential(\n",
    "                nn.Linear(input_dims, fc1_dims),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(fc1_dims, fc2_dims),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(fc2_dims, 1)\n",
    "        )\n",
    "\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=alpha)\n",
    "        self.device = T.device('cuda:0' if T.cuda.is_available() else 'cpu')\n",
    "        self.to(self.device)\n",
    "\n",
    "    def forward(self, state):\n",
    "        value = self.critic(state)\n",
    "\n",
    "        return value\n",
    "\n",
    "    def save_checkpoint(self):\n",
    "        T.save(self.state_dict(), self.checkpoint_file)\n",
    "\n",
    "    def load_checkpoint(self):\n",
    "        self.load_state_dict(T.load(self.checkpoint_file))\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, n_actions, input_dims, gamma=0.99, alpha=0.0003, gae_lambda=0.8,\n",
    "            policy_clip=0.4, batch_size=64, n_epochs=10):\n",
    "        self.gamma = gamma\n",
    "        self.policy_clip = policy_clip\n",
    "        self.n_epochs = n_epochs\n",
    "        self.gae_lambda = gae_lambda\n",
    "\n",
    "        self.actor = ActorNetwork(n_actions, input_dims, alpha)\n",
    "        self.critic = CriticNetwork(input_dims, alpha)\n",
    "        self.memory = PPOMemory(batch_size)\n",
    "        \n",
    "        encoder.optimizer = optim.Adam(encoder.parameters(), lr=alpha)\n",
    "        \n",
    "        encoder.apply(weights_init_normal)\n",
    "        self.critic.apply(weights_init_normal)\n",
    "        self.actor.apply(weights_init_normal)\n",
    "\n",
    "    def remember(self, state, action, probs, vals, reward, done):\n",
    "        self.memory.store_memory(state, action, probs, vals, reward, done)\n",
    "\n",
    "    def save_models(self):\n",
    "        print('... saving models ...')\n",
    "        self.actor.save_checkpoint()\n",
    "        self.critic.save_checkpoint()\n",
    "\n",
    "    def load_models(self):\n",
    "        print('... loading models ...')\n",
    "        self.actor.load_checkpoint()\n",
    "        self.critic.load_checkpoint()\n",
    "\n",
    "    def choose_action(self, observation):\n",
    "        state = T.tensor(observation, dtype=T.float).to(self.actor.device)\n",
    "\n",
    "        dist = self.actor(state)\n",
    "\n",
    "        value = self.critic(state)\n",
    "        #print(\"Distribution\", dist, value)\n",
    "        action = dist.sample()\n",
    "\n",
    "        probs = T.squeeze(dist.log_prob(action)).item()\n",
    "        action = T.squeeze(action).item()\n",
    "        value = T.squeeze(value).item()\n",
    "\n",
    "        return action, probs, value\n",
    "\n",
    "    def learn(self):\n",
    "        for _ in range(self.n_epochs):\n",
    "            state_arr, action_arr, old_prob_arr, vals_arr,\\\n",
    "            reward_arr, dones_arr, batches = \\\n",
    "                    self.memory.generate_batches()\n",
    "\n",
    "            values = vals_arr\n",
    "            advantage = np.zeros(len(reward_arr), dtype=np.float32)\n",
    "\n",
    "            for t in range(len(reward_arr)-1):\n",
    "                discount = 1\n",
    "                a_t = 0\n",
    "                for k in range(t, len(reward_arr)-1):\n",
    "                    a_t += discount*(reward_arr[k] + self.gamma*values[k+1]*\\\n",
    "                            (1-int(dones_arr[k])) - values[k])\n",
    "                    discount *= self.gamma*self.gae_lambda\n",
    "                advantage[t] = a_t\n",
    "            advantage = T.tensor(advantage).to(self.actor.device)\n",
    "\n",
    "            values = T.tensor(values).to(self.actor.device)\n",
    "            for batch in batches:\n",
    "                states = T.tensor(state_arr[batch], dtype=T.float).to(self.actor.device)\n",
    "                old_probs = T.tensor(old_prob_arr[batch]).to(self.actor.device)\n",
    "                actions = T.tensor(action_arr[batch]).to(self.actor.device)\n",
    "\n",
    "                dist = self.actor(states)\n",
    "                critic_value = self.critic(states)\n",
    "\n",
    "                critic_value = T.squeeze(critic_value)\n",
    "\n",
    "                new_probs = dist.log_prob(actions)\n",
    "                prob_ratio = new_probs.exp() / old_probs.exp()\n",
    "                #prob_ratio = (new_probs - old_probs).exp()\n",
    "                print(prob_ratio)\n",
    "                weighted_probs = advantage[batch] * prob_ratio\n",
    "                weighted_clipped_probs = T.clamp(prob_ratio, 1-self.policy_clip,\n",
    "                        1+self.policy_clip)*advantage[batch]\n",
    "                actor_loss = -T.min(weighted_probs, weighted_clipped_probs).mean()\n",
    "\n",
    "                returns = advantage[batch] + values[batch]\n",
    "                critic_loss = (returns-critic_value)**2\n",
    "                critic_loss = critic_loss.mean()\n",
    "\n",
    "                total_loss = actor_loss + 0.5*critic_loss\n",
    "                self.actor.optimizer.zero_grad()\n",
    "                self.critic.optimizer.zero_grad()\n",
    "                encoder.zero_grad()\n",
    "                total_loss.backward()\n",
    "                self.actor.optimizer.step()\n",
    "                self.critic.optimizer.step()\n",
    "                encoder.optimizer.step()\n",
    "\n",
    "        self.memory.clear_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "1EWvoHT1VXlv",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_learning_curve(x, scores, figure_file):\n",
    "    running_avg = np.zeros(len(scores))\n",
    "    for i in range(len(running_avg)):\n",
    "        running_avg[i] = np.mean(scores[max(0, i-100):(i+1)])\n",
    "    plt.plot(x, running_avg)\n",
    "    plt.title('Running average of previous 100 scores')\n",
    "    plt.savefig(figure_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "oc-ibKzWVilR",
    "outputId": "a86d5d0c-9882-4d6f-90c3-576509cc96b8",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                      | 1/1000 [00:04<1:20:20,  4.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target video: 1066681921.mp4 Initial bitrate: 685.30 \n",
      "Chosen bitrate percentage: 0.45 Quality: 94.86\n",
      "Normal(loc: tensor([0.7139], grad_fn=<SelectBackward0>), scale: tensor([0.7503], grad_fn=<SelectBackward0>))\n",
      "[1.00000000e+00 6.85299415e+02 2.34951600e+06 2.98126901e+02\n",
      " 9.85585900e+02 4.35031599e-01 1.02627200e+06 0.00000000e+00\n",
      " 7.06126153e-01 3.33677471e-01 0.00000000e+00 1.12016499e-02\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 2.67484903e-01]\n",
      "-1.1050544261932373 1.5550544261932373\n",
      "Error\n",
      "Chosen bitrate percentage: -1.11 Reward: -5000.00 Quality: 0.00\n",
      "episode 1066681921.mp4 score -5000.0 avg score 0.0 time_steps 1 learning_steps 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                                                     | 2/1000 [00:09<1:22:03,  4.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target video: 1066678921.mp4 Initial bitrate: 673.45 \n",
      "Chosen bitrate percentage: 0.45 Quality: 94.45\n",
      "Normal(loc: tensor([0.5761], grad_fn=<SelectBackward0>), scale: tensor([0.8003], grad_fn=<SelectBackward0>))\n",
      "[1.00000000e+00 6.73445066e+02 2.46003800e+06 2.71970066e+02\n",
      " 9.44728100e+02 4.03848925e-01 8.54872000e+05 0.00000000e+00\n",
      " 6.81035995e-01 3.18202853e-01 0.00000000e+00 6.60716891e-02\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 2.92954981e-01]\n",
      "-1.154423999786377 1.604423999786377\n",
      "Error\n",
      "Chosen bitrate percentage: -1.15 Reward: -5000.00 Quality: 0.00\n",
      "episode 1066678921.mp4 score -5000.0 avg score 0.0 time_steps 2 learning_steps 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                                                     | 3/1000 [00:12<1:07:36,  4.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target video: 1066688005.mp4 Initial bitrate: 864.68 \n",
      "Chosen bitrate percentage: 0.45 Quality: 92.15\n",
      "Normal(loc: tensor([0.7139], grad_fn=<SelectBackward0>), scale: tensor([0.7503], grad_fn=<SelectBackward0>))\n",
      "[1.00000000e+00 8.64680816e+02 1.06362200e+06 3.66750204e+02\n",
      " 7.14658100e+02 4.24145184e-01 4.53642000e+05 0.00000000e+00\n",
      " 6.22346044e-01 3.18301618e-01 0.00000000e+00 6.43554330e-02\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 2.80308455e-01]\n",
      "-0.6872491121292115 1.1372491121292114\n",
      "Error\n",
      "Chosen bitrate percentage: -0.69 Reward: -5000.00 Quality: 0.00\n",
      "episode 1066688005.mp4 score -5000.0 avg score 0.0 time_steps 3 learning_steps 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                     | 4/1000 [00:15<1:00:51,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target video: 1066685137.mp4 Initial bitrate: 926.70 \n",
      "Chosen bitrate percentage: 0.45 Quality: 91.88\n",
      "Normal(loc: tensor([0.7139], grad_fn=<SelectBackward0>), scale: tensor([0.7503], grad_fn=<SelectBackward0>))\n",
      "[1.00000000e+00 9.26703399e+02 1.29996200e+06 4.04598927e+02\n",
      " 6.88176200e+02 4.36600240e-01 5.70170000e+05 0.00000000e+00\n",
      " 7.07810521e-01 3.36504012e-01 0.00000000e+00 8.05694163e-02\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 2.56955951e-01]\n",
      "-0.3345029830932617 0.7845029830932617\n",
      "Error\n",
      "Chosen bitrate percentage: -0.33 Reward: -5000.00 Quality: 0.00\n",
      "episode 1066685137.mp4 score -5000.0 avg score 0.0 time_steps 4 learning_steps 0\n",
      "Target video: 1066679386.mp4 Initial bitrate: 620.22 \n",
      "Chosen bitrate percentage: 0.45 Quality: 95.45\n",
      "Normal(loc: tensor([0.5932], grad_fn=<SelectBackward0>), scale: tensor([0.9111], grad_fn=<SelectBackward0>))\n",
      "[1.00000000e+00 6.20217193e+02 3.03596700e+06 2.93845317e+02\n",
      " 1.04476850e+03 4.73778090e-01 1.44589400e+06 0.00000000e+00\n",
      " 6.95962131e-01 3.26609403e-01 0.00000000e+00 8.60729218e-02\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 2.60638386e-01]\n",
      "1.723282766342163 -1.273282766342163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                     | 5/1000 [00:30<2:08:17,  7.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WTF too high\n",
      "Chosen bitrate percentage: 1.72 Reward: -5000.00 Quality: 0.00\n",
      "episode 1066679386.mp4 score -5000.0 avg score 0.0 time_steps 5 learning_steps 0\n",
      "Target video: 1066695394.mp4 Initial bitrate: 910.45 \n",
      "Chosen bitrate percentage: 0.45 Quality: 78.70\n",
      "Normal(loc: tensor([0.5621], grad_fn=<SelectBackward0>), scale: tensor([0.8678], grad_fn=<SelectBackward0>))\n",
      "[ 1.00000000e+00  9.10451777e+02  3.89726300e+06  4.11127834e+02\n",
      " -6.30312700e+02  4.51564645e-01  2.03454000e+06  0.00000000e+00\n",
      "  6.56488001e-01  3.15205336e-01  0.00000000e+00  6.59445524e-02\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  2.58710504e-01]\n",
      "1.2604963898658752 0.8104963898658752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                                                     | 6/1000 [00:42<2:30:02,  9.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WTF too high\n",
      "Chosen bitrate percentage: 1.26 Reward: -5000.00 Quality: 0.00\n",
      "episode 1066695394.mp4 score -5000.0 avg score 0.0 time_steps 6 learning_steps 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                                                     | 7/1000 [00:49<2:16:22,  8.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target video: 1066722598.mp4 Initial bitrate: 652.80 \n",
      "Chosen bitrate percentage: 0.45 Quality: 91.03\n",
      "Normal(loc: tensor([0.6583], grad_fn=<SelectBackward0>), scale: tensor([0.7732], grad_fn=<SelectBackward0>))\n",
      "[1.00000000e+00 6.52802667e+02 1.48263800e+06 2.87169333e+02\n",
      " 6.03120500e+02 4.39902206e-01 6.59580000e+05 0.00000000e+00\n",
      " 6.57655478e-01 3.24141085e-01 0.00000000e+00 9.89076495e-02\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 2.61186391e-01]\n",
      "-2.0695612907409666 2.519561290740967\n",
      "Error\n",
      "Chosen bitrate percentage: -2.07 Reward: -5000.00 Quality: 0.00\n",
      "episode 1066722598.mp4 score -5000.0 avg score 0.0 time_steps 7 learning_steps 0\n",
      "Target video: 1066684072.mp4 Initial bitrate: 912.31 \n",
      "Chosen bitrate percentage: 0.45 Quality: 82.39\n",
      "Normal(loc: tensor([0.6583], grad_fn=<SelectBackward0>), scale: tensor([0.7732], grad_fn=<SelectBackward0>))\n",
      "[ 1.00000000e+00  9.12314619e+02  3.42911700e+06  4.11776757e+02\n",
      " -2.60876800e+02  4.51353895e-01  1.55026800e+06  0.00000000e+00\n",
      "  6.98631525e-01  3.40614647e-01  0.00000000e+00  5.82551062e-02\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  3.02566051e-01]\n",
      "1.396572184562683 0.9465721845626831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▌                                                                     | 8/1000 [01:01<2:40:45,  9.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WTF too high\n",
      "Chosen bitrate percentage: 1.40 Reward: -5000.00 Quality: 0.00\n",
      "episode 1066684072.mp4 score -5000.0 avg score 0.0 time_steps 8 learning_steps 0\n",
      "Target video: 1066687174.mp4 Initial bitrate: 923.56 \n",
      "Chosen bitrate percentage: 0.45 Quality: 76.69\n",
      "Normal(loc: tensor([0.6583], grad_fn=<SelectBackward0>), scale: tensor([0.7732], grad_fn=<SelectBackward0>))\n",
      "[ 1.00000000e+00  9.23556800e+02  1.73685700e+06  4.14290667e+02\n",
      " -8.31341900e+02  4.48581686e-01  7.82008000e+05  0.00000000e+00\n",
      "  6.69962764e-01  3.31564844e-01  0.00000000e+00  5.96876144e-02\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  2.71961838e-01]\n",
      "1.6473021030426025 1.1973021030426025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▋                                                                     | 9/1000 [01:07<2:20:54,  8.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WTF too high\n",
      "Chosen bitrate percentage: 1.65 Reward: -5000.00 Quality: 0.00\n",
      "episode 1066687174.mp4 score -5000.0 avg score 0.0 time_steps 9 learning_steps 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▋                                                                     | 9/1000 [01:11<2:10:53,  7.92s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 36\u001b[0m\n\u001b[1;32m     32\u001b[0m observation \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mreset( data_dir \u001b[38;5;241m+\u001b[39m i)\n\u001b[1;32m     34\u001b[0m bit_percentage \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.45\u001b[39m\n\u001b[0;32m---> 36\u001b[0m observation, _, done, _ \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbit_percentage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget video:\u001b[39m\u001b[38;5;124m\"\u001b[39m, i, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitial bitrate:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{:.2f}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(env\u001b[38;5;241m.\u001b[39minitial_bitrate), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mChosen bitrate percentage:\u001b[39m\u001b[38;5;124m\"\u001b[39m, bit_percentage, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuality:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{:.2f}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(env\u001b[38;5;241m.\u001b[39mquality))\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m done:\n",
      "Cell \u001b[0;32mIn[23], line 66\u001b[0m, in \u001b[0;36mVideoEncodingEnvironment.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbitrate \u001b[38;5;241m=\u001b[39m ffbs\u001b[38;5;241m.\u001b[39mavg_bitrate\n\u001b[1;32m     65\u001b[0m last_quality \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquality\n\u001b[0;32m---> 66\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquality \u001b[38;5;241m=\u001b[39m \u001b[43mcompare\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_video\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./output.mp4\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# Update size\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mstat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./output.mp4\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mst_size\n",
      "Cell \u001b[0;32mIn[6], line 5\u001b[0m, in \u001b[0;36mcompare\u001b[0;34m(ImageAPath, ImageBPath)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompare\u001b[39m(ImageAPath, ImageBPath):\n\u001b[1;32m      4\u001b[0m     cmd \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./ffmpeg-git-20230621-amd64-static/ffmpeg -i\u001b[39m\u001b[38;5;124m\"\u001b[39m, ImageAPath, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-i\u001b[39m\u001b[38;5;124m\"\u001b[39m, ImageBPath, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-lavfi libvmaf=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_threads=16\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m -f null -\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m----> 5\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetoutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m)\u001b[49m;\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(x\u001b[38;5;241m.\u001b[39msplit()[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[0;32m/usr/lib/python3.11/subprocess.py:691\u001b[0m, in \u001b[0;36mgetoutput\u001b[0;34m(cmd, encoding, errors)\u001b[0m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetoutput\u001b[39m(cmd, \u001b[38;5;241m*\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    682\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return output (stdout or stderr) of executing cmd in a shell.\u001b[39;00m\n\u001b[1;32m    683\u001b[0m \n\u001b[1;32m    684\u001b[0m \u001b[38;5;124;03m    Like getstatusoutput(), except the exit status is ignored and the return\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    689\u001b[0m \u001b[38;5;124;03m    '/bin/ls'\u001b[39;00m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 691\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgetstatusoutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m/usr/lib/python3.11/subprocess.py:671\u001b[0m, in \u001b[0;36mgetstatusoutput\u001b[0;34m(cmd, encoding, errors)\u001b[0m\n\u001b[1;32m    650\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return (exitcode, output) of executing cmd in a shell.\u001b[39;00m\n\u001b[1;32m    651\u001b[0m \n\u001b[1;32m    652\u001b[0m \u001b[38;5;124;03mExecute the string 'cmd' in a shell with 'check_output' and\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    668\u001b[0m \u001b[38;5;124;03m(-15, '')\u001b[39;00m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    670\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 671\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstderr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSTDOUT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    673\u001b[0m     exitcode \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    674\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CalledProcessError \u001b[38;5;28;01mas\u001b[39;00m ex:\n",
      "File \u001b[0;32m/usr/lib/python3.11/subprocess.py:466\u001b[0m, in \u001b[0;36mcheck_output\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    463\u001b[0m         empty \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    464\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m empty\n\u001b[0;32m--> 466\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpopenargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[43m           \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mstdout\n",
      "File \u001b[0;32m/usr/lib/python3.11/subprocess.py:550\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[1;32m    549\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 550\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    552\u001b[0m         process\u001b[38;5;241m.\u001b[39mkill()\n",
      "File \u001b[0;32m/usr/lib/python3.11/subprocess.py:1194\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1192\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stdin_write(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m   1193\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout:\n\u001b[0;32m-> 1194\u001b[0m     stdout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1195\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m   1196\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "import gym\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "env = VideoEncodingEnvironment(\"./WUzgd7C1pWA.mp4\")#gym.make('CartPole-v0')\n",
    "N = 50\n",
    "batch_size = 256\n",
    "n_epochs = 10\n",
    "alpha = 0.005#000005\n",
    "agent = Agent(n_actions=1, batch_size=batch_size,\n",
    "                alpha=alpha, n_epochs=n_epochs,\n",
    "                input_dims=(17), policy_clip=0.3)\n",
    "#agent.load_models()\n",
    "\n",
    "figure_file = 'cartpole.png'\n",
    "\n",
    "best_score = -1000\n",
    "score_history = [] \n",
    "\n",
    "learn_iters = 0\n",
    "avg_score = 0\n",
    "n_steps = 0\n",
    "\n",
    "\n",
    "data_dir = \"data/\"\n",
    "\n",
    "videos = os.listdir(data_dir)\n",
    "random.Random(0).shuffle(videos)\n",
    "\n",
    "for i in tqdm(videos[:1000]):\n",
    "    observation = env.reset( data_dir + i)\n",
    "    \n",
    "    bit_percentage = 0.45\n",
    "    \n",
    "    observation, _, done, _ = env.step(bit_percentage)\n",
    "    \n",
    "    print(\"Target video:\", i, \"Initial bitrate:\", \"{:.2f}\".format(env.initial_bitrate), \"\\nChosen bitrate percentage:\", bit_percentage, \"Quality:\", \"{:.2f}\".format(env.quality))\n",
    "    if done:\n",
    "        continue\n",
    "    done = False\n",
    "    score = 0\n",
    "    while not done:\n",
    "        action, prob, val = agent.choose_action(observation)\n",
    "        \n",
    "        # Get negated sign of quality difference\n",
    "        x = env.quality - 85\n",
    "        sign = (x < 0) - (x > 0)\n",
    "        bit_percentage += sign * action \n",
    "        print(observation)\n",
    "        print(bit_percentage, action)\n",
    "        observation_, reward, done, percentage = env.step(bit_percentage)\n",
    "        print(\"Chosen bitrate percentage:\", \"{:.2f}\".format(float(bit_percentage)), \"Reward:\", \"{:.2f}\".format(reward), \"Quality:\", \"{:.2f}\".format(env.quality))\n",
    "        n_steps += 1\n",
    "        score += reward\n",
    "        agent.remember(observation, action, prob, val, reward, done)\n",
    "        if n_steps % N == 0:\n",
    "            print(\"Learning\")\n",
    "            avg_score = np.mean(score_history[-100:])\n",
    "            if avg_score > best_score:\n",
    "                best_score = avg_score\n",
    "                agent.save_models()\n",
    "            agent.learn()\n",
    "            learn_iters += 1\n",
    "        observation = observation_\n",
    "    score_history.append(score)\n",
    "\n",
    "    print('episode', i, 'score %.1f' % score, 'avg score %.1f' % avg_score,\n",
    "            'time_steps', n_steps, 'learning_steps', learn_iters)\n",
    "x = [i+1 for i in range(len(score_history))]\n",
    "plot_learning_curve(x, score_history, figure_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
