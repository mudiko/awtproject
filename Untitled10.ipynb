{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8FeO0CTHm5_t",
    "outputId": "f1494a16-d69d-41a4-b1c3-dac8712f6005",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch as T\n",
    "T.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7NqTsLiK8wuH",
    "outputId": "23fddcc5-adc7-4a77-c320-495b7e5b2595",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amd64\n"
     ]
    }
   ],
   "source": [
    "!dpkg --print-architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F19DtgKW92y9",
    "outputId": "96c191e4-f24a-4d93-b723-9f35a15b0700",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3lyr\t\t\t\t  ffmpeg-git-amd64-static.tar.xz.3\n",
      "cartpole.png\t\t\t  ffmpeg-git-amd64-static.tar.xz.4\n",
      "data\t\t\t\t  newdata\n",
      "downsample.sh\t\t\t  output.mp4\n",
      "extracted.jpg\t\t\t  ppo\n",
      "ffmpeg-git-20230621-amd64-static  Untitled10.ipynb\n",
      "ffmpeg-git-amd64-static.tar.xz\t  v2.3.1.tar.gz\n",
      "ffmpeg-git-amd64-static.tar.xz.1  vmaf-2.3.1\n",
      "ffmpeg-git-amd64-static.tar.xz.2  WUzgd7C1pWA.mp4\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hr17uYPX85vm",
    "outputId": "bb6051ff-e154-4539-f934-be4e3d28b775",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Download ffmpeg\n",
    "\n",
    "#!wget https://johnvansickle.com/ffmpeg/builds/ffmpeg-git-amd64-static.tar.xz\n",
    "#!tar -xf ffmpeg-git-amd64-static.tar.xz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "LcmKQgf4Fbw2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.autograd import Variable\n",
    "from skimage.metrics import structural_similarity\n",
    "import imageio.v3 as iio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "71ZpaFgEFwQk",
    "outputId": "59e7e39c-6b4e-4fab-ad2e-e86116582f6c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./WUzgd7C1pWA.mp4\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets.utils import download_url\n",
    "\n",
    "download_url(\n",
    "    \"https://github.com/pytorch/vision/blob/main/test/assets/videos/WUzgd7C1pWA.mp4?raw=true\",\n",
    "    \".\",\n",
    "    \"WUzgd7C1pWA.mp4\"\n",
    ")\n",
    "video_path = \"./WUzgd7C1pWA.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vo1dwfHa9zvy",
    "outputId": "01c03960-437e-4abc-93f9-8da0fd03e96a",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg version n6.0 Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with gcc 12.2.1 (GCC) 20230201\n",
      "  configuration: --prefix=/usr --disable-debug --disable-static --disable-stripping --enable-amf --enable-avisynth --enable-cuda-llvm --enable-lto --enable-fontconfig --enable-gmp --enable-gnutls --enable-gpl --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libdav1d --enable-libdrm --enable-libfreetype --enable-libfribidi --enable-libgsm --enable-libiec61883 --enable-libjack --enable-libjxl --enable-libmfx --enable-libmodplug --enable-libmp3lame --enable-libopencore_amrnb --enable-libopencore_amrwb --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librav1e --enable-librsvg --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtheora --enable-libv4l2 --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxcb --enable-libxml2 --enable-libxvid --enable-libzimg --enable-nvdec --enable-nvenc --enable-opencl --enable-opengl --enable-shared --enable-version3 --enable-vulkan\n",
      "  libavutil      58.  2.100 / 58.  2.100\n",
      "  libavcodec     60.  3.100 / 60.  3.100\n",
      "  libavformat    60.  3.100 / 60.  3.100\n",
      "  libavdevice    60.  1.100 / 60.  1.100\n",
      "  libavfilter     9.  3.100 /  9.  3.100\n",
      "  libswscale      7.  1.100 /  7.  1.100\n",
      "  libswresample   4. 10.100 /  4. 10.100\n",
      "  libpostproc    57.  1.100 / 57.  1.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'WUzgd7C1pWA.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf56.25.101\n",
      "  Duration: 00:00:10.91, start: 0.000000, bitrate: 652 kb/s\n",
      "  Stream #0:0[0x1](und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(progressive), 340x256 [SAR 1:1 DAR 85:64], 562 kb/s, 29.97 fps, 29.97 tbr, 30k tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "  Stream #0:1[0x2](eng): Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, mono, fltp, 80 kb/s (default)\n",
      "    Metadata:\n",
      "      handler_name    : SoundHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (h264 (native) -> h264 (libx264))\n",
      "  Stream #0:1 -> #0:1 (aac (native) -> aac (native))\n",
      "Press [q] to stop, [?] for help\n",
      "\u001b[1;36m[libx264 @ 0x558b14998580] \u001b[0musing SAR=1/1\n",
      "\u001b[1;36m[libx264 @ 0x558b14998580] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "\u001b[1;36m[libx264 @ 0x558b14998580] \u001b[0mprofile High, level 1.3, 4:2:0, 8-bit\n",
      "\u001b[1;36m[libx264 @ 0x558b14998580] \u001b[0m264 - core 164 r3095 baee400 - H.264/MPEG-4 AVC codec - Copyleft 2003-2022 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=8 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=35.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to 'output.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf60.3.100\n",
      "  Stream #0:0(und): Video: h264 (avc1 / 0x31637661), yuv420p(progressive), 340x256 [SAR 1:1 DAR 85:64], q=2-31, 29.97 fps, 30k tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc60.3.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
      "  Stream #0:1(eng): Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, mono, fltp, 69 kb/s (default)\n",
      "    Metadata:\n",
      "      handler_name    : SoundHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc60.3.100 aac\n",
      "frame=  327 fps=0.0 q=-1.0 Lsize=     292kB time=00:00:10.88 bitrate= 219.6kbits/s speed=13.7x    \n",
      "video:187kB audio:92kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 4.604194%\n",
      "\u001b[1;36m[libx264 @ 0x558b14998580] \u001b[0mframe I:2     Avg QP:36.30  size:  2520\n",
      "\u001b[1;36m[libx264 @ 0x558b14998580] \u001b[0mframe P:138   Avg QP:38.47  size:   933\n",
      "\u001b[1;36m[libx264 @ 0x558b14998580] \u001b[0mframe B:187   Avg QP:42.01  size:   302\n",
      "\u001b[1;36m[libx264 @ 0x558b14998580] \u001b[0mconsecutive B-frames: 13.5% 26.3% 13.8% 46.5%\n",
      "\u001b[1;36m[libx264 @ 0x558b14998580] \u001b[0mmb I  I16..4: 11.6% 75.9% 12.5%\n",
      "\u001b[1;36m[libx264 @ 0x558b14998580] \u001b[0mmb P  I16..4:  4.5%  7.5%  0.6%  P16..4: 46.3%  9.0%  3.1%  0.0%  0.0%    skip:28.9%\n",
      "\u001b[1;36m[libx264 @ 0x558b14998580] \u001b[0mmb B  I16..4:  0.2%  0.5%  0.0%  B16..8: 38.3%  2.1%  0.1%  direct: 0.5%  skip:58.3%  L0:42.0% L1:56.7% BI: 1.2%\n",
      "\u001b[1;36m[libx264 @ 0x558b14998580] \u001b[0m8x8 transform intra:61.2% inter:82.5%\n",
      "\u001b[1;36m[libx264 @ 0x558b14998580] \u001b[0mcoded y,uvDC,uvAC intra: 29.4% 34.6% 3.2% inter: 7.1% 5.4% 0.1%\n",
      "\u001b[1;36m[libx264 @ 0x558b14998580] \u001b[0mi16 v,h,dc,p: 18% 44% 12% 27%\n",
      "\u001b[1;36m[libx264 @ 0x558b14998580] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 14% 23% 35%  3%  5%  6%  5%  4%  5%\n",
      "\u001b[1;36m[libx264 @ 0x558b14998580] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 22% 24% 26%  4%  5%  7%  5%  4%  4%\n",
      "\u001b[1;36m[libx264 @ 0x558b14998580] \u001b[0mi8c dc,h,v,p: 78% 13%  7%  2%\n",
      "\u001b[1;36m[libx264 @ 0x558b14998580] \u001b[0mWeighted P-Frames: Y:5.8% UV:0.7%\n",
      "\u001b[1;36m[libx264 @ 0x558b14998580] \u001b[0mref P L0: 73.0% 13.5% 10.1%  3.2%  0.1%\n",
      "\u001b[1;36m[libx264 @ 0x558b14998580] \u001b[0mref B L0: 92.3%  6.7%  1.0%\n",
      "\u001b[1;36m[libx264 @ 0x558b14998580] \u001b[0mref B L1: 97.9%  2.1%\n",
      "\u001b[1;36m[libx264 @ 0x558b14998580] \u001b[0mkb/s:139.56\n",
      "\u001b[1;36m[aac @ 0x558b149c93c0] \u001b[0mQavg: 124.327\n"
     ]
    }
   ],
   "source": [
    "!rm output.mp4\n",
    "!ffmpeg -i WUzgd7C1pWA.mp4 -vcodec libx264 -crf 35 -acodec aac output.mp4 > /dev/null\n",
    "#!ffmpeg -i WUzgd7C1pWA.mp4 -b:v 2M output.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eUtk7m3p7MVz",
    "outputId": "f2d5c8ea-9415-40fe-bb1e-6fe06df4b2ee",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg version N-66244-g468615f204-static https://johnvansickle.com/ffmpeg/  Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with gcc 8 (Debian 8.3.0-6)\n",
      "  configuration: --enable-gpl --enable-version3 --enable-static --disable-debug --disable-ffplay --disable-indev=sndio --disable-outdev=sndio --cc=gcc --enable-fontconfig --enable-frei0r --enable-gnutls --enable-gmp --enable-libgme --enable-gray --enable-libaom --enable-libfribidi --enable-libass --enable-libvmaf --enable-libfreetype --enable-libmp3lame --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-librubberband --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libvorbis --enable-libopus --enable-libtheora --enable-libvidstab --enable-libvo-amrwbenc --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libdav1d --enable-libxvid --enable-libzvbi --enable-libzimg\n",
      "  libavutil      58. 13.101 / 58. 13.101\n",
      "  libavcodec     60. 21.100 / 60. 21.100\n",
      "  libavformat    60.  9.100 / 60.  9.100\n",
      "  libavdevice    60.  2.100 / 60.  2.100\n",
      "  libavfilter     9.  8.102 /  9.  8.102\n",
      "  libswscale      7.  3.100 /  7.  3.100\n",
      "  libswresample   4. 11.100 /  4. 11.100\n",
      "  libpostproc    57.  2.100 / 57.  2.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'WUzgd7C1pWA.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf56.25.101\n",
      "  Duration: 00:00:10.91, start: 0.000000, bitrate: 652 kb/s\n",
      "  Stream #0:0[0x1](und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(progressive), 340x256 [SAR 1:1 DAR 85:64], 562 kb/s, 29.97 fps, 29.97 tbr, 30k tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "  Stream #0:1[0x2](eng): Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, mono, fltp, 80 kb/s (default)\n",
      "    Metadata:\n",
      "      handler_name    : SoundHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "Input #1, mov,mp4,m4a,3gp,3g2,mj2, from 'output.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf60.3.100\n",
      "  Duration: 00:00:23.45, start: 0.000000, bitrate: 101 kb/s\n",
      "  Stream #1:0[0x1](und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(tv, bt709, progressive), 596x336 [SAR 1:1 DAR 149:84], 92 kb/s, 25 fps, 25 tbr, 12800 tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc60.3.100 libx264\n",
      "  Stream #1:1[0x2](und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 2 kb/s (default)\n",
      "    Metadata:\n",
      "      handler_name    : SoundHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "Stream mapping:\n",
      "  Stream #0:0 (h264) -> libvmaf (graph 0)\n",
      "  Stream #1:0 (h264) -> libvmaf (graph 0)\n",
      "  libvmaf:default (graph 0) -> Stream #0:0 (wrapped_avframe)\n",
      "  Stream #1:1 -> #0:1 (aac (native) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "\u001b[1;32m[Parsed_libvmaf_0 @ 0x7965300] \u001b[0m\u001b[1;31minput width must match.\n",
      "\u001b[0m\u001b[1;32m[Parsed_libvmaf_0 @ 0x7965300] \u001b[0m\u001b[1;31minput height must match.\n",
      "\u001b[0m\u001b[1;32m[Parsed_libvmaf_0 @ 0x7965300] \u001b[0m\u001b[1;31mFailed to configure input pad on Parsed_libvmaf_0\n",
      "\u001b[0m\u001b[1;32m[fc#0 @ 0x5c4cac0] \u001b[0m\u001b[1;31mError reinitializing filters!\n",
      "\u001b[0m\u001b[1;31mFailed to inject frame into filter network: Invalid argument\n",
      "\u001b[0m\u001b[4;31mInvalid argument\n",
      "\u001b[0mConversion failed!\n"
     ]
    }
   ],
   "source": [
    "!./ffmpeg-git-20230621-amd64-static/ffmpeg -i WUzgd7C1pWA.mp4 -i output.mp4 -lavfi libvmaf -f null -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "IDXqFCeJIP2q",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import subprocess\n",
    "def compare(ImageAPath, ImageBPath):\n",
    "    cmd = \" \".join([\"./ffmpeg-git-20230621-amd64-static/ffmpeg -i\", ImageAPath, \"-i\", ImageBPath, \"-lavfi libvmaf -f null -\"])\n",
    "    x = subprocess.getoutput(cmd);\n",
    "    return float(x.split()[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PCH_WHlCIbSB",
    "outputId": "e14395f1-3863-4ed9-abdc-98c77a82596e",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81.55542"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare(\"./WUzgd7C1pWA.mp4\", \"./output.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "09kv90GuOYA3",
    "outputId": "37da85b0-ceb1-4fd1-e9db-c6da8c11836c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mudiko/.local/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/mudiko/.local/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "#RESNET50 can be replaced by something faster and better\n",
    "\n",
    "resnet50 = models.resnet50(pretrained=True)\n",
    "modules=list(resnet50.children())[:-1]\n",
    "resnet50 = nn.Sequential(*modules)\n",
    "\n",
    "# Set to false to stop training image part\n",
    "for p in resnet50.parameters():\n",
    "    p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Copyright (c) Meta Platforms, Inc. and affiliates.\n",
    "#\n",
    "# This source code is licensed under the MIT license found in the\n",
    "# LICENSE file in the root directory of this source tree.\n",
    "\n",
    "\n",
    "# from https://github.com/toshas/torch_truncnorm\n",
    "\n",
    "import math\n",
    "from numbers import Number\n",
    "\n",
    "import torch\n",
    "from torch.distributions import constraints, Distribution\n",
    "from torch.distributions.utils import broadcast_all\n",
    "\n",
    "CONST_SQRT_2 = math.sqrt(2)\n",
    "CONST_INV_SQRT_2PI = 1 / math.sqrt(2 * math.pi)\n",
    "CONST_INV_SQRT_2 = 1 / math.sqrt(2)\n",
    "CONST_LOG_INV_SQRT_2PI = math.log(CONST_INV_SQRT_2PI)\n",
    "CONST_LOG_SQRT_2PI_E = 0.5 * math.log(2 * math.pi * math.e)\n",
    "\n",
    "\n",
    "class TruncatedStandardNormal(Distribution):\n",
    "    \"\"\"Truncated Standard Normal distribution.\n",
    "    Source: https://people.sc.fsu.edu/~jburkardt/presentations/truncated_normal.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    arg_constraints = {\n",
    "        \"a\": constraints.real,\n",
    "        \"b\": constraints.real,\n",
    "    }\n",
    "    has_rsample = True\n",
    "    eps = 1e-6\n",
    "\n",
    "    def __init__(self, a, b, validate_args=None):\n",
    "        self.a, self.b = broadcast_all(a, b)\n",
    "        if isinstance(a, Number) and isinstance(b, Number):\n",
    "            batch_shape = torch.Size()\n",
    "        else:\n",
    "            batch_shape = self.a.size()\n",
    "        super(TruncatedStandardNormal, self).__init__(\n",
    "            batch_shape, validate_args=validate_args\n",
    "        )\n",
    "        if self.a.dtype != self.b.dtype:\n",
    "            raise ValueError(\"Truncation bounds types are different\")\n",
    "        if any(\n",
    "            (self.a >= self.b)\n",
    "            .view(\n",
    "                -1,\n",
    "            )\n",
    "            .tolist()\n",
    "        ):\n",
    "            raise ValueError(\"Incorrect truncation range\")\n",
    "        eps = self.eps\n",
    "        self._dtype_min_gt_0 = eps\n",
    "        self._dtype_max_lt_1 = 1 - eps\n",
    "        self._little_phi_a = self._little_phi(self.a)\n",
    "        self._little_phi_b = self._little_phi(self.b)\n",
    "        self._big_phi_a = self._big_phi(self.a)\n",
    "        self._big_phi_b = self._big_phi(self.b)\n",
    "        self._Z = (self._big_phi_b - self._big_phi_a).clamp(eps, 1 - eps)\n",
    "        self._log_Z = self._Z.log()\n",
    "        little_phi_coeff_a = torch.nan_to_num(self.a, nan=math.nan)\n",
    "        little_phi_coeff_b = torch.nan_to_num(self.b, nan=math.nan)\n",
    "        self._lpbb_m_lpaa_d_Z = (\n",
    "            self._little_phi_b * little_phi_coeff_b\n",
    "            - self._little_phi_a * little_phi_coeff_a\n",
    "        ) / self._Z\n",
    "        self._mean = -(self._little_phi_b - self._little_phi_a) / self._Z\n",
    "        self._variance = (\n",
    "            1\n",
    "            - self._lpbb_m_lpaa_d_Z\n",
    "            - ((self._little_phi_b - self._little_phi_a) / self._Z) ** 2\n",
    "        )\n",
    "        self._entropy = CONST_LOG_SQRT_2PI_E + self._log_Z - 0.5 * self._lpbb_m_lpaa_d_Z\n",
    "\n",
    "    @constraints.dependent_property\n",
    "    def support(self):\n",
    "        return constraints.interval(self.a, self.b)\n",
    "\n",
    "    @property\n",
    "    def mean(self):\n",
    "        return self._mean\n",
    "\n",
    "    @property\n",
    "    def variance(self):\n",
    "        return self._variance\n",
    "\n",
    "    @property\n",
    "    def entropy(self):\n",
    "        return self._entropy\n",
    "\n",
    "    @property\n",
    "    def auc(self):\n",
    "        return self._Z\n",
    "\n",
    "    @staticmethod\n",
    "    def _little_phi(x):\n",
    "        return (-(x**2) * 0.5).exp() * CONST_INV_SQRT_2PI\n",
    "\n",
    "    def _big_phi(self, x):\n",
    "        phi = 0.5 * (1 + (x * CONST_INV_SQRT_2).erf())\n",
    "        return phi.clamp(self.eps, 1 - self.eps)\n",
    "\n",
    "    @staticmethod\n",
    "    def _inv_big_phi(x):\n",
    "        return CONST_SQRT_2 * (2 * x - 1).erfinv()\n",
    "\n",
    "    def cdf(self, value):\n",
    "        if self._validate_args:\n",
    "            self._validate_sample(value)\n",
    "        return ((self._big_phi(value) - self._big_phi_a) / self._Z).clamp(0, 1)\n",
    "\n",
    "    def icdf(self, value):\n",
    "        y = self._big_phi_a + value * self._Z\n",
    "        y = y.clamp(self.eps, 1 - self.eps)\n",
    "        return self._inv_big_phi(y)\n",
    "\n",
    "    def log_prob(self, value):\n",
    "        if self._validate_args:\n",
    "            self._validate_sample(value)\n",
    "        return CONST_LOG_INV_SQRT_2PI - self._log_Z - (value**2) * 0.5\n",
    "\n",
    "    def rsample(self, sample_shape=None):\n",
    "        if sample_shape is None:\n",
    "            sample_shape = torch.Size([])\n",
    "        shape = self._extended_shape(sample_shape)\n",
    "        p = torch.empty(shape, device=self.a.device).uniform_(\n",
    "            self._dtype_min_gt_0, self._dtype_max_lt_1\n",
    "        )\n",
    "        return self.icdf(p)\n",
    "\n",
    "\n",
    "class TruncatedNormal(TruncatedStandardNormal):\n",
    "    \"\"\"Truncated Normal distribution.\n",
    "    https://people.sc.fsu.edu/~jburkardt/presentations/truncated_normal.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    has_rsample = True\n",
    "\n",
    "    def __init__(self, loc, scale, a, b, validate_args=None):\n",
    "        scale = scale.clamp_min(self.eps)\n",
    "        self.loc, self.scale, a, b = broadcast_all(loc, scale, a, b)\n",
    "        self._non_std_a = a\n",
    "        self._non_std_b = b\n",
    "        a = (a - self.loc) / self.scale\n",
    "        b = (b - self.loc) / self.scale\n",
    "        super(TruncatedNormal, self).__init__(a, b, validate_args=validate_args)\n",
    "        self._log_scale = self.scale.log()\n",
    "        self._mean = self._mean * self.scale + self.loc\n",
    "        self._variance = self._variance * self.scale**2\n",
    "        self._entropy += self._log_scale\n",
    "\n",
    "    def _to_std_rv(self, value):\n",
    "        return (value - self.loc) / self.scale\n",
    "\n",
    "    def _from_std_rv(self, value):\n",
    "        return value * self.scale + self.loc\n",
    "\n",
    "    def cdf(self, value):\n",
    "        return super(TruncatedNormal, self).cdf(self._to_std_rv(value))\n",
    "\n",
    "    def icdf(self, value):\n",
    "        sample = self._from_std_rv(super().icdf(value))\n",
    "\n",
    "        # clamp data but keep gradients\n",
    "        sample_clip = torch.stack(\n",
    "            [sample.detach(), self._non_std_a.detach().expand_as(sample)], 0\n",
    "        ).max(0)[0]\n",
    "        sample_clip = torch.stack(\n",
    "            [sample_clip, self._non_std_b.detach().expand_as(sample)], 0\n",
    "        ).min(0)[0]\n",
    "        sample.data.copy_(sample_clip)\n",
    "        return sample\n",
    "\n",
    "    def log_prob(self, value):\n",
    "        value = self._to_std_rv(value)\n",
    "        return super(TruncatedNormal, self).log_prob(value) - self._log_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L80JDPWFIgSa",
    "outputId": "98aa6e12-42a7-41a2-9c98-f929b68ee7c2",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: ffmpeg-bitrate-stats in /home/mudiko/.local/lib/python3.11/site-packages (0.4.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install ffmpeg-bitrate-stats\n",
    "from ffmpeg_bitrate_stats import BitrateStats\n",
    "\n",
    "import os\n",
    "import gym\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "\n",
    "import subprocess\n",
    "\n",
    "game_steps = 5\n",
    "\n",
    "class VideoEncodingEnvironment(gym.Env):\n",
    "    def __init__(self, target_video):\n",
    "        super(VideoEncodingEnvironment, self).__init__()\n",
    "\n",
    "        self.target_video = target_video  # Target video representation\n",
    "        #self.max_steps = max_steps  # Maximum number of steps for encoding\n",
    "\n",
    "        self.current_step = 0  # Current step in the encoding process\n",
    "        \n",
    "        self.size = os.stat(target_video).st_size  # Current video representation\n",
    "        self.initial_size = self.size\n",
    "        \n",
    "        ffbs = BitrateStats(target_video)\n",
    "        ffbs.calculate_statistics()\n",
    "\n",
    "        self.create_embedding()\n",
    "\n",
    "        self.bitrate = ffbs.avg_bitrate\n",
    "\n",
    "        self.quality = 100\n",
    "        \n",
    "        self.initial_bitrate = 0\n",
    "        \n",
    "        self.prev_score = 0\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    def step(self, action):\n",
    "        # Update step count\n",
    "        self.current_step += 1\n",
    "        \n",
    "        action = action * self.initial_bitrate * 1000\n",
    "        \n",
    "        print(\"Chosen bitrate:\", action)\n",
    "\n",
    "        # Calculate quality\n",
    "        os.remove(\"./output.mp4\") if os.path.exists(\"./output.mp4\") else None\n",
    "        cmd = \" \".join([\"ffmpeg -i\", self.target_video, \"-b:v\", str(int(action)), \"./output.mp4\", \"-hide_banner\", \"-loglevel error\"])\n",
    "        x = subprocess.run(cmd, shell = True, stdout = subprocess.DEVNULL, stderr=subprocess.PIPE);\n",
    "        \n",
    "        if x.stderr.decode() != \"\":\n",
    "            print(\"Error\")\n",
    "            self.quality = 0\n",
    "            state = np.array([[self.current_step, self.initial_bitrate, self. initial_size, self.bitrate, self.quality, self.size]])\n",
    "            state = np.concatenate((state, self.embed.reshape((1,-1)).detach().numpy()), axis = 1).reshape(-1)\n",
    "            return state, -500, True, \"\"\n",
    "\n",
    "        ffbs = BitrateStats(\"./output.mp4\")\n",
    "        ffbs.calculate_statistics()\n",
    "        self.bitrate = ffbs.avg_bitrate\n",
    "\n",
    "\n",
    "        self.quality = compare(self.target_video, \"./output.mp4\")\n",
    "        print(\"Quality:\", self.quality)\n",
    "\n",
    "        # Update size\n",
    "        self.size = os.stat(\"./output.mp4\").st_size\n",
    "\n",
    "        state = np.array([[self.current_step, self.initial_bitrate, self. initial_size, self.bitrate, self.quality, self.size]])\n",
    "        state = np.concatenate((state, self.embed.reshape((1,-1)).detach().numpy()), axis = 1).reshape(-1)\n",
    "        \n",
    "        \n",
    "        target_reached = self.quality > 84 and self.quality < 86\n",
    "                \n",
    "        # Reward\n",
    "\n",
    "        score = 225 - ((self.quality - 85)**2) \n",
    "        \n",
    "        if self.quality > 92:\n",
    "            score -= (self.quality - 92) * 12.5\n",
    "        \n",
    "        if self.bitrate > self.initial_bitrate:\n",
    "            print(\"WTF too high\")\n",
    "            self.quality = 0\n",
    "            state = np.array([[self.current_step, self.initial_bitrate, self. initial_size, self.bitrate, self.quality, self.size]])\n",
    "            state = np.concatenate((state, self.embed.reshape((1,-1)).detach().numpy()), axis = 1).reshape(-1)\n",
    "            return state, -500, True, \"\"\n",
    "            \n",
    "        \n",
    "        #Give bonus for reaching target\n",
    "        if target_reached:\n",
    "            score = score + (200 * (game_steps + 1 - self.current_step)) \n",
    "        \n",
    "        reward = score - self.prev_score - ((abs(self.quality - 85)/1.5) ** 2 ) - 10\n",
    "        if self.current_step == 1:\n",
    "            reward -= 80\n",
    "        self.prev_score = score\n",
    "        \n",
    "        print(reward)\n",
    "        \n",
    "        return state, reward, self.current_step > (game_steps - 1) or target_reached, \"\"\n",
    "\n",
    "    def create_embedding(self):\n",
    "        #Create embedding for a single image\n",
    "        from PIL import Image\n",
    "        #Extract the first frame\n",
    "        #Can be possible to do more efficiently without iio.imiter\n",
    "        iio.imwrite(\"extracted.jpg\", list(iio.imiter(self.target_video))[0])\n",
    "        import torchvision.transforms as transforms\n",
    "        transform = transforms.Compose([transforms.PILToTensor()])\n",
    "        img = Image.open(\"extracted.jpg\")\n",
    "        tensor = transform(img)\n",
    "        tensor = tensor.unsqueeze(0).float()\n",
    "        self.embed = resnet50(tensor).reshape(-1)\n",
    "\n",
    "    def reset(self, target_video):\n",
    "        self.target_video = target_video\n",
    "        self.current_step = 0  # Current step in the encoding process\n",
    "        self.prev_score = 0\n",
    "        self.reward = 0\n",
    "        self.size = os.stat(self.target_video).st_size  # Current video representation\n",
    "        self.initial_size = self.size\n",
    "\n",
    "\n",
    "        ffbs = BitrateStats(self.target_video)\n",
    "        ffbs.calculate_statistics()\n",
    "        self.bitrate = ffbs.avg_bitrate\n",
    "        print(target_video, self.bitrate)\n",
    "        \n",
    "        self.initial_bitrate = self.bitrate\n",
    "\n",
    "\n",
    "        self.quality = 100\n",
    "\n",
    "        self.create_embedding()\n",
    "        state = np.array([[self.current_step, self.initial_bitrate, self. initial_size, self.bitrate, self.quality, self.size]])\n",
    "        state = np.concatenate((state, self.embed.reshape((1,-1)).detach().numpy()), axis = 1).reshape(-1)\n",
    "\n",
    "        return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZYMHfAMkQTql",
    "outputId": "21d49f84-75de-4ad1-c82a-5c05807854b5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘ppo’: File exists\n"
     ]
    }
   ],
   "source": [
    "%mkdir ppo\n",
    "import os\n",
    "import numpy as np\n",
    "import torch as T\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.distributions.normal import Normal\n",
    "from torch.distributions.beta import Beta\n",
    "\n",
    "import torchrl\n",
    "\n",
    "class PPOMemory:\n",
    "    def __init__(self, batch_size):\n",
    "        self.states = []\n",
    "        self.probs = []\n",
    "        self.vals = []\n",
    "        self.actions = []\n",
    "        self.rewards = []\n",
    "        self.dones = []\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def generate_batches(self):\n",
    "        n_states = len(self.states)\n",
    "        batch_start = np.arange(0, n_states, self.batch_size)\n",
    "        indices = np.arange(n_states, dtype=np.int64)\n",
    "        np.random.shuffle(indices)\n",
    "        batches = [indices[i:i+self.batch_size] for i in batch_start]\n",
    "\n",
    "        return np.array(self.states),\\\n",
    "                np.array(self.actions),\\\n",
    "                np.array(self.probs),\\\n",
    "                np.array(self.vals),\\\n",
    "                np.array(self.rewards),\\\n",
    "                np.array(self.dones),\\\n",
    "                batches\n",
    "\n",
    "    def store_memory(self, state, action, probs, vals, reward, done):\n",
    "        self.states.append(state)\n",
    "        self.actions.append(action)\n",
    "        self.probs.append(probs)\n",
    "        self.vals.append(vals)\n",
    "        self.rewards.append(reward)\n",
    "        self.dones.append(done)\n",
    "\n",
    "    def clear_memory(self):\n",
    "        self.states = []\n",
    "        self.probs = []\n",
    "        self.actions = []\n",
    "        self.rewards = []\n",
    "        self.dones = []\n",
    "        self.vals = []\n",
    "\n",
    "class ActorNetwork(nn.Module):\n",
    "    def __init__(self, n_actions, input_dims, alpha,\n",
    "            fc1_dims=256, fc2_dims=256, chkpt_dir='ppo'):\n",
    "        super(ActorNetwork, self).__init__()\n",
    "\n",
    "        self.checkpoint_file = os.path.join(chkpt_dir, 'actor_torch_ppo')\n",
    "        self.actor = nn.Sequential(\n",
    "                nn.Linear(input_dims, fc1_dims),\n",
    "                nn.Sigmoid(),\n",
    "                nn.Linear(fc1_dims, fc2_dims),\n",
    "                nn.Sigmoid(),\n",
    "                nn.Linear(fc1_dims, fc2_dims),\n",
    "                nn.Sigmoid(),\n",
    "                nn.Linear(fc2_dims, 2)\n",
    "        )\n",
    "\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=alpha)\n",
    "        self.device = T.device('cuda:0' if T.cuda.is_available() else 'cpu')\n",
    "        self.to(self.device)\n",
    "\n",
    "    def forward(self, state):\n",
    "        dist = self.actor(state)\n",
    "        #print(state.shape)\n",
    "        dist = torch.abs(dist).reshape(-1,2)\n",
    "        #print(dist.shape)\n",
    "        #dist = Normal(dist[:,0] , 4 * torch.sqrt(dist[:,1]))\n",
    "        #dist = Beta(dist[:,0] , dist[:,1])\n",
    "        print(dist)\n",
    "        dist = TruncatedNormal(dist[:,0] , dist[:,1] , 0, 1)\n",
    "        return dist\n",
    "\n",
    "    def save_checkpoint(self):\n",
    "        T.save(self.state_dict(), self.checkpoint_file)\n",
    "\n",
    "    def load_checkpoint(self):\n",
    "        self.load_state_dict(T.load(self.checkpoint_file))\n",
    "\n",
    "class CriticNetwork(nn.Module):\n",
    "    def __init__(self, input_dims, alpha, fc1_dims=256, fc2_dims=256,\n",
    "            chkpt_dir='ppo'):\n",
    "        super(CriticNetwork, self).__init__()\n",
    "\n",
    "        self.checkpoint_file = os.path.join(chkpt_dir, 'critic_torch_ppo')\n",
    "        self.critic = nn.Sequential(\n",
    "                nn.Linear(input_dims, fc1_dims),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(fc1_dims, fc2_dims),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(fc2_dims, 1)\n",
    "        )\n",
    "\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=alpha)\n",
    "        self.device = T.device('cuda:0' if T.cuda.is_available() else 'cpu')\n",
    "        self.to(self.device)\n",
    "\n",
    "    def forward(self, state):\n",
    "        value = self.critic(state)\n",
    "\n",
    "        return value\n",
    "\n",
    "    def save_checkpoint(self):\n",
    "        T.save(self.state_dict(), self.checkpoint_file)\n",
    "\n",
    "    def load_checkpoint(self):\n",
    "        self.load_state_dict(T.load(self.checkpoint_file))\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, n_actions, input_dims, gamma=0.99, alpha=0.0003, gae_lambda=0.95,\n",
    "            policy_clip=0.1, batch_size=64, n_epochs=10):\n",
    "        self.gamma = gamma\n",
    "        self.policy_clip = policy_clip\n",
    "        self.n_epochs = n_epochs\n",
    "        self.gae_lambda = gae_lambda\n",
    "\n",
    "        self.actor = ActorNetwork(n_actions, input_dims, alpha)\n",
    "        self.critic = CriticNetwork(input_dims, alpha)\n",
    "        self.memory = PPOMemory(batch_size)\n",
    "\n",
    "    def remember(self, state, action, probs, vals, reward, done):\n",
    "        self.memory.store_memory(state, action, probs, vals, reward, done)\n",
    "\n",
    "    def save_models(self):\n",
    "        print('... saving models ...')\n",
    "        self.actor.save_checkpoint()\n",
    "        self.critic.save_checkpoint()\n",
    "\n",
    "    def load_models(self):\n",
    "        print('... loading models ...')\n",
    "        self.actor.load_checkpoint()\n",
    "        self.critic.load_checkpoint()\n",
    "\n",
    "    def choose_action(self, observation):\n",
    "        state = T.tensor(observation, dtype=T.float).to(self.actor.device)\n",
    "\n",
    "        dist = self.actor(state)\n",
    "\n",
    "        value = self.critic(state)\n",
    "        print(\"Distribution\", dist, value)\n",
    "        action = dist.sample()\n",
    "\n",
    "        probs = T.squeeze(dist.log_prob(action)).item()\n",
    "        action = T.squeeze(action).item()\n",
    "        value = T.squeeze(value).item()\n",
    "\n",
    "        return action, probs, value\n",
    "\n",
    "    def learn(self):\n",
    "        for _ in range(self.n_epochs):\n",
    "            state_arr, action_arr, old_prob_arr, vals_arr,\\\n",
    "            reward_arr, dones_arr, batches = \\\n",
    "                    self.memory.generate_batches()\n",
    "\n",
    "            values = vals_arr\n",
    "            advantage = np.zeros(len(reward_arr), dtype=np.float32)\n",
    "\n",
    "            for t in range(len(reward_arr)-1):\n",
    "                discount = 1\n",
    "                a_t = 0\n",
    "                for k in range(t, len(reward_arr)-1):\n",
    "                    a_t += discount*(reward_arr[k] + self.gamma*values[k+1]*\\\n",
    "                            (1-int(dones_arr[k])) - values[k])\n",
    "                    discount *= self.gamma*self.gae_lambda\n",
    "                advantage[t] = a_t\n",
    "            advantage = T.tensor(advantage).to(self.actor.device)\n",
    "\n",
    "            values = T.tensor(values).to(self.actor.device)\n",
    "            for batch in batches:\n",
    "                states = T.tensor(state_arr[batch], dtype=T.float).to(self.actor.device)\n",
    "                old_probs = T.tensor(old_prob_arr[batch]).to(self.actor.device)\n",
    "                actions = T.tensor(action_arr[batch]).to(self.actor.device)\n",
    "\n",
    "                dist = self.actor(states)\n",
    "                critic_value = self.critic(states)\n",
    "\n",
    "                critic_value = T.squeeze(critic_value)\n",
    "\n",
    "                new_probs = dist.log_prob(actions)\n",
    "                prob_ratio = new_probs.exp() / old_probs.exp()\n",
    "                #prob_ratio = (new_probs - old_probs).exp()\n",
    "                weighted_probs = advantage[batch] * prob_ratio\n",
    "                weighted_clipped_probs = T.clamp(prob_ratio, 1-self.policy_clip,\n",
    "                        1+self.policy_clip)*advantage[batch]\n",
    "                actor_loss = -T.min(weighted_probs, weighted_clipped_probs).mean()\n",
    "\n",
    "                returns = advantage[batch] + values[batch]\n",
    "                critic_loss = (returns-critic_value)**2\n",
    "                critic_loss = critic_loss.mean()\n",
    "\n",
    "                total_loss = actor_loss + 0.5*critic_loss\n",
    "                self.actor.optimizer.zero_grad()\n",
    "                self.critic.optimizer.zero_grad()\n",
    "                total_loss.backward()\n",
    "                self.actor.optimizer.step()\n",
    "                self.critic.optimizer.step()\n",
    "\n",
    "        self.memory.clear_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "1EWvoHT1VXlv",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_learning_curve(x, scores, figure_file):\n",
    "    running_avg = np.zeros(len(scores))\n",
    "    for i in range(len(running_avg)):\n",
    "        running_avg[i] = np.mean(scores[max(0, i-100):(i+1)])\n",
    "    plt.plot(x, running_avg)\n",
    "    plt.title('Running average of previous 100 scores')\n",
    "    plt.savefig(figure_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "oc-ibKzWVilR",
    "outputId": "a86d5d0c-9882-4d6f-90c3-576509cc96b8",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                 | 0/509 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newdata/data/1066678336.mp4 495.8044368600683\n",
      "tensor([[0.1729, 0.0337]], grad_fn=<ReshapeAliasBackward0>)\n",
      "Distribution TruncatedNormal(a: tensor([-51.2513], grad_fn=<DivBackward0>), b: tensor([245.1453], grad_fn=<DivBackward0>)) tensor([699.7424], grad_fn=<AddBackward0>)\n",
      "Chosen bitrate: 84035.76052808315\n",
      "Quality: 75.479196\n",
      "4.067309501843596\n",
      "tensor([[0.1831, 0.0412]], grad_fn=<ReshapeAliasBackward0>)\n",
      "Distribution TruncatedNormal(a: tensor([-44.4436], grad_fn=<DivBackward0>), b: tensor([198.2229], grad_fn=<DivBackward0>)) tensor([104.4284], grad_fn=<AddBackward0>)\n",
      "Chosen bitrate: 92590.97359481525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                 | 0/509 [00:31<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[103], line 38\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[1;32m     37\u001b[0m     action, prob, val \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mchoose_action(observation)\n\u001b[0;32m---> 38\u001b[0m     observation_, reward, done, info \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m     n_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     40\u001b[0m     score \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n",
      "Cell \u001b[0;32mIn[99], line 66\u001b[0m, in \u001b[0;36mVideoEncodingEnvironment.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     62\u001b[0m ffbs\u001b[38;5;241m.\u001b[39mcalculate_statistics()\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbitrate \u001b[38;5;241m=\u001b[39m ffbs\u001b[38;5;241m.\u001b[39mavg_bitrate\n\u001b[0;32m---> 66\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquality \u001b[38;5;241m=\u001b[39m \u001b[43mcompare\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_video\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./output.mp4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuality:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquality)\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# Update size\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[95], line 5\u001b[0m, in \u001b[0;36mcompare\u001b[0;34m(ImageAPath, ImageBPath)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompare\u001b[39m(ImageAPath, ImageBPath):\n\u001b[1;32m      4\u001b[0m     cmd \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./ffmpeg-git-20230621-amd64-static/ffmpeg -i\u001b[39m\u001b[38;5;124m\"\u001b[39m, ImageAPath, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-i\u001b[39m\u001b[38;5;124m\"\u001b[39m, ImageBPath, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-lavfi libvmaf -f null -\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m----> 5\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetoutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m)\u001b[49m;\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(x\u001b[38;5;241m.\u001b[39msplit()[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[0;32m/usr/lib/python3.11/subprocess.py:691\u001b[0m, in \u001b[0;36mgetoutput\u001b[0;34m(cmd, encoding, errors)\u001b[0m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetoutput\u001b[39m(cmd, \u001b[38;5;241m*\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    682\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return output (stdout or stderr) of executing cmd in a shell.\u001b[39;00m\n\u001b[1;32m    683\u001b[0m \n\u001b[1;32m    684\u001b[0m \u001b[38;5;124;03m    Like getstatusoutput(), except the exit status is ignored and the return\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    689\u001b[0m \u001b[38;5;124;03m    '/bin/ls'\u001b[39;00m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 691\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgetstatusoutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m/usr/lib/python3.11/subprocess.py:671\u001b[0m, in \u001b[0;36mgetstatusoutput\u001b[0;34m(cmd, encoding, errors)\u001b[0m\n\u001b[1;32m    650\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return (exitcode, output) of executing cmd in a shell.\u001b[39;00m\n\u001b[1;32m    651\u001b[0m \n\u001b[1;32m    652\u001b[0m \u001b[38;5;124;03mExecute the string 'cmd' in a shell with 'check_output' and\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    668\u001b[0m \u001b[38;5;124;03m(-15, '')\u001b[39;00m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    670\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 671\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstderr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSTDOUT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    673\u001b[0m     exitcode \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    674\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CalledProcessError \u001b[38;5;28;01mas\u001b[39;00m ex:\n",
      "File \u001b[0;32m/usr/lib/python3.11/subprocess.py:466\u001b[0m, in \u001b[0;36mcheck_output\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    463\u001b[0m         empty \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    464\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m empty\n\u001b[0;32m--> 466\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpopenargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[43m           \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mstdout\n",
      "File \u001b[0;32m/usr/lib/python3.11/subprocess.py:550\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[1;32m    549\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 550\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    552\u001b[0m         process\u001b[38;5;241m.\u001b[39mkill()\n",
      "File \u001b[0;32m/usr/lib/python3.11/subprocess.py:1194\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1192\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stdin_write(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m   1193\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout:\n\u001b[0;32m-> 1194\u001b[0m     stdout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1195\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m   1196\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "import gym\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "env = VideoEncodingEnvironment(\"./WUzgd7C1pWA.mp4\")#gym.make('CartPole-v0')\n",
    "N = 20\n",
    "batch_size = 256\n",
    "n_epochs = 20\n",
    "alpha = 0.0003\n",
    "agent = Agent(n_actions=1, batch_size=batch_size,\n",
    "                alpha=alpha, n_epochs=n_epochs,\n",
    "                input_dims=(2054))\n",
    "#agent.load_models()\n",
    "\n",
    "figure_file = 'cartpole.png'\n",
    "\n",
    "best_score = -1000\n",
    "score_history = [] \n",
    "\n",
    "learn_iters = 0\n",
    "avg_score = 0\n",
    "n_steps = 0\n",
    "\n",
    "\n",
    "data_dir = \"newdata/data/\"\n",
    "\n",
    "videos = os.listdir(data_dir)\n",
    "random.Random(0).shuffle(videos)\n",
    "\n",
    "\n",
    "for i in tqdm(videos[:1000]):\n",
    "    observation = env.reset( data_dir + i)\n",
    "    done = False\n",
    "    score = 0\n",
    "    while not done:\n",
    "        action, prob, val = agent.choose_action(observation)\n",
    "        observation_, reward, done, info = env.step(action)\n",
    "        n_steps += 1\n",
    "        score += reward\n",
    "        agent.remember(observation, action, prob, val, reward, done)\n",
    "        if n_steps % N == 0:\n",
    "            print(\"Learning\")\n",
    "            avg_score = np.mean(score_history[-100:])\n",
    "            if avg_score > best_score:\n",
    "                best_score = avg_score\n",
    "                agent.save_models()\n",
    "            agent.learn()\n",
    "            learn_iters += 1\n",
    "        observation = observation_\n",
    "    score_history.append(score)\n",
    "\n",
    "    print('episode', i, 'score %.1f' % score, 'avg score %.1f' % avg_score,\n",
    "            'time_steps', n_steps, 'learning_steps', learn_iters)\n",
    "x = [i+1 for i in range(len(score_history))]\n",
    "plot_learning_curve(x, score_history, figure_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffbs = BitrateStats(\"./output.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ffbs.calculate_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
